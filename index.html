<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiaer Xia</title>
  
  <meta name="author" content="Jiaer Xia">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiaer Xia(Â§è‰Ω≥Â∞î)</name>
              </p>
              <p>I'm a second-year master's student at the <a href="https://informatics.xmu.edu.cn/">School of Informatics</a>, Xiamen University, China. I'm a member of <a href="https://mac.xmu.edu.cn/">MACLab</a>, supervised by Professor <a href="https://mac.xmu.edu.cn/rrji/">RongRong Ji</a>.
              </p>
              <p>
                At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="jackson.xje@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?pli=1&authuser=1&user=pdrckAQAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.cn/incareer/in/ACoAACWMLNoBgC6FeVCAy2LE_OBqClrTHBM2EUI">linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/JiaerXia">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests lie at the intersection of machine learning and computer vision, with specialization in person re-identification, cross-modality retrieval, representation learning and domain generalization.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="image/ADP.png" alt="safs_small" width="160" height="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2303.10976">
          <papertitle>Attention Disturbance and Dual-Path Constraint Network for Occluded Person Re-Identification</papertitle>
        </a>
        <br>
        <strong>Jiaer Xia</strong>, <a href="https://scholar.google.com/citations?user=QTnulp0AAAAJ&hl=zh-CN&oi=sra">Lei Tan</a>, <a href="https://scholar.google.com/citations?user=fEw3__QAAAAJ&hl=zh-CN&oi=ao">Pingyang Dai</a>, <a href="https://scholar.google.com/citations?user=3X2iuacAAAAJ&hl=zh-CN&oi=ao">Mingbo Zhao</a>, Yongjian Wu, <a href="https://scholar.google.com/citations?user=lRSD7PQAAAAJ&hl=zh-CN&oi=ao">Rongrong Ji</a>
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2303.10976">arXiv</a>
        <p>Our approach creatively employs an attack strategy to create a highly efficient synthetic occlusion that closely mimics real-world occlusions at the feature level.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="image/Cycle.png" alt="safs_small" width="160" height="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2303.10976">
          <papertitle>CycleTrans: Learning Neutral yet Discriminative Features for Visible-Infrared Person Re-Identification</papertitle>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?hl=zh-CN&user=HyKLYKYAAAAJ">Qiong Wu</a>, <strong>Jiaer Xia</strong>, <a href="https://scholar.google.com/citations?user=fEw3__QAAAAJ&hl=zh-CN&oi=ao">Pingyang Dai</a>, <a href="https://scholar.google.com/citations?user=w3_2ep0AAAAJ&hl=zh-CN&oi=ao">Yiyi Zhou</a>, Yongjian Wu, <a href="https://scholar.google.com/citations?user=lRSD7PQAAAAJ&hl=zh-CN&oi=ao">Rongrong Ji</a>
        <br>
        <em>arXiv</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2303.10976">arXiv</a>
        <p>We propose a novel CycleTrans method to preserve a richer set of semantic information when mapping two modalities to the same feature space.</p>
      </td>
    </tr>

					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
